{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "\n",
    "def read_data(label_url, image_url):\n",
    "    with gzip.open(label_url) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(image_url, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return (label, image)\n",
    "\n",
    "path='/home/ec2-user/MNIST_data/'\n",
    "(train_lbl, train_img) = read_data(\n",
    "    path+'train-labels-idx1-ubyte.gz', path+'train-images-idx3-ubyte.gz')\n",
    "(val_lbl, val_img) = read_data(\n",
    "    path+'t10k-labels-idx1-ubyte.gz', path+'t10k-images-idx3-ubyte.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# mxnet related\n",
    "import mxnet as mx\n",
    "\n",
    "def to4d(img):\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)\n",
    "\n",
    "#\n",
    "# Create a place holder variable for the input data\n",
    "data = mx.sym.Variable('data')\n",
    "# Flatten the data from 4-D shape (batch_size, num_channel, width, height)\n",
    "# into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.Flatten(data=data)\n",
    "\n",
    "# The first fully-connected layer\n",
    "fc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "# Apply relu to the output of the first fully-connnected layer\n",
    "act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the according activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n",
    "\n",
    "# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\n",
    "fc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=10)\n",
    "# The softmax and loss layer\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')\n",
    "\n",
    "# We visualize the network structure with output size (the batch_size is ignored.)\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "# mx.viz.plot_network(symbol=mlp, shape=shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [cpu(0)]\n",
      "INFO:root:Epoch[0] Batch [200]\tSpeed: 47780.37 samples/sec\tTrain-accuracy=0.111350\n",
      "INFO:root:Epoch[0] Batch [400]\tSpeed: 47553.04 samples/sec\tTrain-accuracy=0.110400\n",
      "INFO:root:Epoch[0] Batch [600]\tSpeed: 47619.85 samples/sec\tTrain-accuracy=0.139400\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=1.301\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.272200\n",
      "INFO:root:Epoch[1] Batch [200]\tSpeed: 48014.83 samples/sec\tTrain-accuracy=0.421350\n",
      "INFO:root:Epoch[1] Batch [400]\tSpeed: 47791.66 samples/sec\tTrain-accuracy=0.747900\n",
      "INFO:root:Epoch[1] Batch [600]\tSpeed: 47732.92 samples/sec\tTrain-accuracy=0.833550\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=1.261\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.840400\n",
      "INFO:root:Epoch[2] Batch [200]\tSpeed: 47859.83 samples/sec\tTrain-accuracy=0.863050\n",
      "INFO:root:Epoch[2] Batch [400]\tSpeed: 47700.71 samples/sec\tTrain-accuracy=0.885100\n",
      "INFO:root:Epoch[2] Batch [600]\tSpeed: 47507.28 samples/sec\tTrain-accuracy=0.906150\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=1.265\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.904100\n",
      "INFO:root:Epoch[3] Batch [200]\tSpeed: 47933.92 samples/sec\tTrain-accuracy=0.918500\n",
      "INFO:root:Epoch[3] Batch [400]\tSpeed: 47634.59 samples/sec\tTrain-accuracy=0.924100\n",
      "INFO:root:Epoch[3] Batch [600]\tSpeed: 47683.54 samples/sec\tTrain-accuracy=0.937900\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=1.263\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.934800\n",
      "INFO:root:Epoch[4] Batch [200]\tSpeed: 47865.89 samples/sec\tTrain-accuracy=0.942200\n",
      "INFO:root:Epoch[4] Batch [400]\tSpeed: 47665.01 samples/sec\tTrain-accuracy=0.944450\n",
      "INFO:root:Epoch[4] Batch [600]\tSpeed: 47797.60 samples/sec\tTrain-accuracy=0.953200\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=1.262\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.948500\n",
      "INFO:root:Epoch[5] Batch [200]\tSpeed: 47960.61 samples/sec\tTrain-accuracy=0.954250\n",
      "INFO:root:Epoch[5] Batch [400]\tSpeed: 47752.30 samples/sec\tTrain-accuracy=0.955600\n",
      "INFO:root:Epoch[5] Batch [600]\tSpeed: 47751.29 samples/sec\tTrain-accuracy=0.960950\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=1.260\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.956500\n",
      "INFO:root:Epoch[6] Batch [200]\tSpeed: 47941.72 samples/sec\tTrain-accuracy=0.962950\n",
      "INFO:root:Epoch[6] Batch [400]\tSpeed: 47582.47 samples/sec\tTrain-accuracy=0.963250\n",
      "INFO:root:Epoch[6] Batch [600]\tSpeed: 47690.13 samples/sec\tTrain-accuracy=0.967000\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=1.263\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.961100\n",
      "INFO:root:Epoch[7] Batch [200]\tSpeed: 47980.50 samples/sec\tTrain-accuracy=0.967350\n",
      "INFO:root:Epoch[7] Batch [400]\tSpeed: 55573.46 samples/sec\tTrain-accuracy=0.969000\n",
      "INFO:root:Epoch[7] Batch [600]\tSpeed: 59866.46 samples/sec\tTrain-accuracy=0.971300\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=1.117\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.963800\n",
      "INFO:root:Epoch[8] Batch [200]\tSpeed: 60155.99 samples/sec\tTrain-accuracy=0.971750\n",
      "INFO:root:Epoch[8] Batch [400]\tSpeed: 55724.15 samples/sec\tTrain-accuracy=0.972650\n",
      "INFO:root:Epoch[8] Batch [600]\tSpeed: 50228.39 samples/sec\tTrain-accuracy=0.974800\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=1.096\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.966400\n",
      "INFO:root:Epoch[9] Batch [200]\tSpeed: 49165.90 samples/sec\tTrain-accuracy=0.974300\n",
      "INFO:root:Epoch[9] Batch [400]\tSpeed: 48994.01 samples/sec\tTrain-accuracy=0.975700\n",
      "INFO:root:Epoch[9] Batch [600]\tSpeed: 48995.70 samples/sec\tTrain-accuracy=0.977600\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=1.231\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.969500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as 7 with probability 0.999215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "model = mx.model.FeedForward(\n",
    "    symbol = mlp,       # network structure\n",
    "    num_epoch = 10,     # number of data passes for training\n",
    "    learning_rate = 0.1 # learning rate of SGD\n",
    ")\n",
    "model.fit(\n",
    "    X=train_iter,       # training data\n",
    "    eval_data=val_iter, # validation data\n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n",
    ")\n",
    "\n",
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "# plt.imshow(val_img[0], cmap='Greys_r')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "prob = model.predict(val_img[0:1].astype(np.float32)/255)[0]\n",
    "assert max(prob) > 0.99, \"Low prediction accuracy.\"\n",
    "print 'Classified as %d with probability %f' % (prob.argmax(), max(prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
